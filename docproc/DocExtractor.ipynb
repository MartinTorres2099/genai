{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5c42a8c-c809-47f7-a14f-cd320151fc76",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Python Script for Document Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1d1a96e-6654-4ed0-bb36-916e6ce28f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output saved to ./reports/arrest_reports/output.csv\n"
     ]
    }
   ],
   "source": [
    "#import packages\n",
    "import os\n",
    "import csv\n",
    "from PyPDF2 import PdfReader\n",
    "import pandas as pd\n",
    "\n",
    "#helper functions\n",
    "def process_text(text):\n",
    "    # Split the text into lines\n",
    "    lines = text.strip().split('\\n')\n",
    "\n",
    "    # Create an empty dictionary\n",
    "    data_dict = {}\n",
    "\n",
    "    # Iterate over the lines and extract the key-value pairs\n",
    "    for i, line in enumerate(lines):\n",
    "        if line.endswith(':'):\n",
    "            key = line.strip(':')\n",
    "            value = lines[i+1].strip() if i+1 < len(lines) else \"\"\n",
    "            if key == 'Location of Arrest':\n",
    "                j = i+2\n",
    "                while j < len(lines) and not lines[j].endswith(':'):\n",
    "                    value += ' ' + lines[j].strip()\n",
    "                    j += 1\n",
    "            data_dict[key] = value\n",
    "    return data_dict\n",
    "\n",
    "def extract_pdf_information(pdf_path):\n",
    "    try:\n",
    "        pdf = PdfReader(pdf_path)\n",
    "        \n",
    "        # Extract text from each page of the PDF\n",
    "        text = \"\"\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text()\n",
    "        \n",
    "        # Process the extracted text as needed (e.g., split into fields, clean up data)\n",
    "        # Modify the code below according to your specific data structure and requirements\n",
    "        \n",
    "        #process text\n",
    "        extracted_data_dict = process_text(text)\n",
    "        \n",
    "#         # Split the text into lines\n",
    "#         lines = text.split(\"\\n\")\n",
    "#         print(text)\n",
    "        \n",
    "#         # Remove empty lines\n",
    "#         lines = [line for line in lines if line.strip()]\n",
    "#         print(lines)\n",
    "        \n",
    "#         # Extract relevant data (not fool-proof)\n",
    "#         lines = lines[1::2] \n",
    "#         print(lines)\n",
    "        \n",
    "#         # Split each line into fields based on a delimiter (e.g., \":\")\n",
    "#         extracted_data = [line.split(\":\") for line in lines]\n",
    "#         #print(extracted_data)\n",
    "        \n",
    "        return extracted_data_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while processing {pdf_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def process_pdfs(directory):\n",
    "    # Create an empty list to store the combined information from all PDFs\n",
    "    #combined_data = []\n",
    "    combined_data = pd.DataFrame()\n",
    "\n",
    "    # Iterate over all PDF files in the specified directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Extract information from each PDF\n",
    "            data = extract_pdf_information(pdf_path)\n",
    "            #print(data)\n",
    "\n",
    "            if data is not None:\n",
    "                # Append the extracted data to the combined data list\n",
    "                #combined_data.extend(data)\n",
    "                df_dictionary = pd.DataFrame([data])\n",
    "                combined_data = pd.concat([combined_data, df_dictionary], ignore_index=True)\n",
    "    \n",
    "    # Add headers to the combined data\n",
    "    #combined_data.insert(0, [\"Arresting Officer\", \"Suspect Name\", \"Date of Arrest\", \"Location of Arrest\", \"Incident Description\"])\n",
    "    #check\n",
    "    #print(combined_data.head(2))\n",
    "\n",
    "\n",
    "    # Write the combined data to a CSV file\n",
    "    output_file = os.path.join(directory, \"arrest_report_data.csv\")\n",
    "    # with open(output_file, \"w\", newline=\"\") as csv_file:\n",
    "    #     writer = csv.writer(csv_file)\n",
    "    #     writer.writerows(combined_data)\n",
    "    combined_data.to_csv(output_file, index=False)\n",
    "    print(f\"Output saved to {output_file}\")\n",
    "\n",
    "# Specify the directory containing the generated PDFs\n",
    "pdf_directory = \"./reports/arrest_reports/\"\n",
    "\n",
    "# Process the PDFs and generate the output CSV\n",
    "process_pdfs(pdf_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca9bc97-381d-4c1b-b48a-21f2b9ec2c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3e83b8-ee7a-4820-aeec-087384a239c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
